{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#text classification analysis\n",
        "import pandas as pd\n",
        "df_copy=pd.read_excel('/content/SENTIMENT DATA.xlsx')\n",
        "df_copy['COMMENTS']\n",
        "#bringing everything to lower case\n",
        "df_copy[\"COMMENTS\"]=df_copy[\"COMMENTS\"].apply(lambda x:\" \".join(x.lower() for x in str(x).split()))\n",
        "#REMOVE PUNCTUATIONS\n",
        "df_copy[\"COMMENTS\"]=df_copy[\"COMMENTS\"].str.replace('[^\\w\\s]','')\n",
        "df_copy['COMMENTS']\n",
        "#REMOVE digits\n",
        "df_copy[\"COMMENTS\"]=df_copy[\"COMMENTS\"].str.replace('\\d+','')\n",
        "#stop words IDENTIFYING\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop= stopwords.words('english')\n",
        "stop\n",
        "#manually removing repeating stopwords such as companuy name\n",
        "stop.append('unlock')\n",
        "\n",
        "#REMOVING STOPWORDS FROM DF COPY\n",
        "df_copy['COMMENTS']=df_copy[\"COMMENTS\"].apply(lambda x:\" \".join(x for x in x.split() if x not in stop))\n",
        "df_copy['COMMENTS'].head()\n",
        "#stemming \n",
        "from nltk.stem import PorterStemmer\n",
        "st=PorterStemmer()\n",
        "df_copy['COMMENTS']=df_copy['COMMENTS'].apply(lambda x:\" \".join([st.stem(word) for word in x.split()]))\n",
        "#text data has been cleaned\n",
        "\n",
        "#bag of words - to create numeric data out of textual content\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv=CountVectorizer()\n",
        "x=cv.fit_transform(df_copy['COMMENTS']).toarray()\n",
        "x\n",
        "#getting data into csv sheet\n",
        "import numpy\n",
        "numpy.savetxt(\"foo.csv\", x, delimiter=\",\")\n",
        "#there are no headders\n",
        "a=cv.get_feature_names()\n",
        "a\n",
        "#adding the names to a csv sheet\n",
        "df=pd.DataFrame(a)\n",
        "df.to_csv('foo1.csv',index=False)\n",
        "\n",
        "#determining polarity- if its a negetive or a positive comment\n",
        "#x is bag of words and y will be polarity so splittig data into train and test to assign y\n",
        "y=df_copy['POLARITY']\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test=train_test_split(x,y, test_size=0.20, random_state=0)\n",
        "x_train\n",
        "x_train.shape\n",
        "x_test.shape\n",
        "\n",
        "#logistic regression model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf=LogisticRegression()\n",
        "clf.fit(x_train, y_train)\n",
        "#to summarise bring in pre built function\n",
        "def show_most_informative_features(vectorizer, clf, n=25):\n",
        "  d={}\n",
        "  a=0\n",
        "  feature_names=vectorizer.get_feature_names()\n",
        "  coefs_with_fns=sorted(zip(clf.coef_[0],feature_names))\n",
        "  top= zip(coefs_with_fns[:n], coefs_with_fns[:-(n+1):-1])\n",
        "  print(\"\\t\\tNegetive\\t\\t\\tPositive\")\n",
        "  print(\"______________________________________________________________\")\n",
        "  for(coef_1, fn_1),(coef_2, fn_2) in top:\n",
        "    print(\"\\t%.4f\\t%.15s\\t\\t\\t\\t%.4f\\t%-15s\"%(coef_1, fn_1, coef_2, fn_2))\n",
        "    d[a]=fn_1\n",
        "    a+=1\n",
        "show_most_informative_features(cv,clf)\n",
        "\n",
        "#model evaluation-using model on test data\n",
        "#predicting y\n",
        "y_pred=clf.predict(x_test)\n",
        "y_pred\n",
        "y_test\n",
        "#both are similar but not completely accurate\n",
        "#to test how accurate model is\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred))\n",
        "#72% accuracy determined\n",
        "#_____________________________________________________________________________________________\n",
        "#model deployment when polarity is not given(new data)\n",
        "import pandas as pd\n",
        "df_copy=pd.read_excel(\"/content/predict_comment.xlsx\")\n",
        "#bringing everything to lower case\n",
        "df_copy[\"COMMENTS\"]=df_copy[\"COMMENTS\"].apply(lambda x:\" \".join(x.lower() for x in str(x).split()))\n",
        "#REMOVE PUNCTUATIONS\n",
        "df_copy[\"COMMENTS\"]=df_copy[\"COMMENTS\"].str.replace('[^\\w\\s]','')\n",
        "df_copy['COMMENTS']\n",
        "#REMOVE digits\n",
        "df_copy[\"COMMENTS\"]=df_copy[\"COMMENTS\"].str.replace('\\d+','')\n",
        "#stop words IDENTIFYING\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop= stopwords.words('english')\n",
        "stop\n",
        "#manually removing repeating stopwords such as companuy name\n",
        "stop.append('unlock')\n",
        "\n",
        "#REMOVING STOPWORDS FROM DF COPY\n",
        "df_copy['COMMENTS']=df_copy[\"COMMENTS\"].apply(lambda x:\" \".join(x for x in x.split() if x not in stop))\n",
        "df_copy['COMMENTS'].head()\n",
        "#stemming \n",
        "from nltk.stem import PorterStemmer\n",
        "st=PorterStemmer()\n",
        "df_copy['COMMENTS']=df_copy['COMMENTS'].apply(lambda x:\" \".join([st.stem(word) for word in x.split()]))\n",
        "#text data has been cleaned\n",
        "\n",
        "#bring new data into old bag od words created\n",
        "feature_list= cv.get_feature_names()\n",
        "vect= CountVectorizer(vocabulary= feature_list)\n",
        "x=vect.transform(df_copy['COMMENTS']).toarray()\n",
        "y_pred=clf.predict(x)\n",
        "y_pred\n",
        "#_______________________________________________________________________-"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd3xKSWQnp_M",
        "outputId": "9d6194c9-ed1b-4118-d2f1-4129974a52ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/openpyxl/worksheet/_reader.py:312: UserWarning: Unknown extension is not supported and will be removed\n",
            "  warn(msg)\n",
            "<ipython-input-66-2f0a9f0a7a82>:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df_copy[\"COMMENTS\"]=df_copy[\"COMMENTS\"].str.replace('[^\\w\\s]','')\n",
            "<ipython-input-66-2f0a9f0a7a82>:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df_copy[\"COMMENTS\"]=df_copy[\"COMMENTS\"].str.replace('\\d+','')\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "<ipython-input-66-2f0a9f0a7a82>:89: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df_copy[\"COMMENTS\"]=df_copy[\"COMMENTS\"].str.replace('[^\\w\\s]','')\n",
            "<ipython-input-66-2f0a9f0a7a82>:92: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df_copy[\"COMMENTS\"]=df_copy[\"COMMENTS\"].str.replace('\\d+','')\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\tNegetive\t\t\tPositive\n",
            "______________________________________________________________\n",
            "\t-0.9010\tlack\t\t\t\t0.8508\tmaintain       \n",
            "\t-0.8374\tlead\t\t\t\t0.7639\tidea           \n",
            "\t-0.8374\tengag\t\t\t\t0.7319\tachiev         \n",
            "\t-0.7679\trecord\t\t\t\t0.7279\tpolici         \n",
            "\t-0.7125\tsupport\t\t\t\t0.6913\tabil           \n",
            "\t-0.6651\tfail\t\t\t\t0.6907\tmistak         \n",
            "\t-0.6394\tone\t\t\t\t0.6805\tbetter         \n",
            "\t-0.6378\tfavor\t\t\t\t0.6802\tfutur          \n",
            "\t-0.6231\tcomplain\t\t\t\t0.6796\tstrong         \n",
            "\t-0.6089\tpoor\t\t\t\t0.6788\tmake           \n",
            "\t-0.6012\tinstruct\t\t\t\t0.6749\twhenev         \n",
            "\t-0.5895\task\t\t\t\t0.6736\trespons        \n",
            "\t-0.5852\tnotic\t\t\t\t0.6639\tinstanc        \n",
            "\t-0.5780\tattitud\t\t\t\t0.6599\thandl          \n",
            "\t-0.5592\ttool\t\t\t\t0.6333\tgive           \n",
            "\t-0.5551\tobject\t\t\t\t0.6246\ttechnic        \n",
            "\t-0.5528\tunabl\t\t\t\t0.6228\tunderstand     \n",
            "\t-0.5208\tmind\t\t\t\t0.6138\texist          \n",
            "\t-0.5183\tmet\t\t\t\t0.6082\tconvers        \n",
            "\t-0.5177\tnewer\t\t\t\t0.6037\tmonitor        \n",
            "\t-0.5129\tmotiv\t\t\t\t0.5987\tlate           \n",
            "\t-0.5011\tunrealist\t\t\t\t0.5940\taccount        \n",
            "\t-0.4884\tsignificantli\t\t\t\t0.5679\tcustom         \n",
            "\t-0.4848\tanalyz\t\t\t\t0.5607\tchalleng       \n",
            "\t-0.4800\toutcom\t\t\t\t0.5579\tmani           \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.71      0.72        48\n",
            "           1       0.70      0.73      0.71        44\n",
            "\n",
            "    accuracy                           0.72        92\n",
            "   macro avg       0.72      0.72      0.72        92\n",
            "weighted avg       0.72      0.72      0.72        92\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
              "       0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "       1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
              "       0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
              "       1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
              "       1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#bringing everything to lower case\n",
        "df_copy[\"COMMENTS\"]=df_copy[\"COMMENTS\"].apply(lambda x:\" \".join(x.lower() for x in str(x).split()))"
      ],
      "metadata": {
        "id": "2k7-oF-qpxk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy[\"COMMENTS\"]"
      ],
      "metadata": {
        "id": "LyO33ODnrGzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#REMOVE PUNCTUATIONS\n",
        "df_copy[\"COMMENTS\"]=df_copy[\"COMMENTS\"].str.replace('[^\\w\\s]','')\n",
        "df_copy['COMMENTS']\n",
        "#REMOVE digits\n",
        "df_copy[\"COMMENTS\"]=df_copy[\"COMMENTS\"].str.replace('\\d+','')"
      ],
      "metadata": {
        "id": "J3hgjYEF9coY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stop words IDENTIFYING\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop=stopwords.words('english')\n",
        "stop\n",
        "\n"
      ],
      "metadata": {
        "id": "X6wRdR1rPMcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stemming \n",
        "from nltk.stem import PorterStemmer\n",
        "st=PorterStemmer()\n",
        "df_copy['COMMENTS']=df_copy['COMMENTS'].apply(lambda x:\" \".join([st.stem(word) for word in x.split()]))\n",
        "#text data has been cleaned"
      ],
      "metadata": {
        "id": "FPKHyehO1w31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bag of words - to create numeric data out of textual content\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv=CountVectorizer()\n",
        "x=cv.fit_transform(df_copy['COMMENTS']).toarray()\n",
        "x\n"
      ],
      "metadata": {
        "id": "gSOmERkD3QQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop=stopwords.words('english')"
      ],
      "metadata": {
        "id": "6Sj-oRyH6u45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#determining polarity- if its a negetive or a positive comment\n",
        "#x is bag of words and y will be polarity so splittig data into train and test to assign y\n",
        "y=df_copy['POLARITY']\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test=train_test_split(x,y, test_size=0.20, random_state=0)\n",
        "x_train\n",
        "x_train.shape\n",
        "x_test.shape"
      ],
      "metadata": {
        "id": "9F402S_KlXqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#logistic regression model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf=LogisticRegression()\n",
        "clf.fit(x_train, y_train)\n"
      ],
      "metadata": {
        "id": "KjYXv1L_ofKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to summarise bring in pre built function\n",
        "def show_most_informative_features(vectorizer, clf, n=25):\n",
        "  d={}\n",
        "  a=0\n",
        "  feature_names=vectorizer.get_feature_names()\n",
        "  coefs_with_fns=sorted(zip(clf.coef_[0],feature_names))\n",
        "  top= zip(coefs_with_fns[:n], coefs_with_fns[:-(n+1):-1])\n",
        "  print(\"\\t\\tNegetive\\t\\t\\tPositive\")\n",
        "  print(\"______________________________________________________________\")\n",
        "  for(coef_1, fn_1),(coef_2, fn_2) in top:\n",
        "    print(\"\\t%.4f\\t%.15s\\t\\t\\t\\t%.4f\\t%-15s\"%(coef_1, fn_1, coef_2, fn_2))\n",
        "    d[a]=fn_1\n",
        "    a+=1\n",
        "show_most_informative_features(cv,clf)"
      ],
      "metadata": {
        "id": "hOou8RAOsYWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model evaluation-using model on test data\n",
        "#predicting y\n",
        "y_pred=clf.predict(x_test)\n",
        "y_pred\n",
        "y_test\n",
        "#both are similar but not completely accurate\n",
        "#to test how accurate model is\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred))\n",
        "#72% accuracy determined"
      ],
      "metadata": {
        "id": "6AXLKuE0kRP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model deployment when polarity is not given(new data)\n",
        "import pandas as pd\n",
        "df_copy=pd.read_excel(\"/content/predict_comment.xlsx\")\n",
        "#bringing everything to lower case\n",
        "df_copy[\"COMMENTS\"]=df_copy[\"COMMENTS\"].apply(lambda x:\" \".join(x.lower() for x in str(x).split()))\n",
        "#REMOVE PUNCTUATIONS\n",
        "df_copy[\"COMMENTS\"]=df_copy[\"COMMENTS\"].str.replace('[^\\w\\s]','')\n",
        "df_copy['COMMENTS']\n",
        "#REMOVE digits\n",
        "df_copy[\"COMMENTS\"]=df_copy[\"COMMENTS\"].str.replace('\\d+','')\n",
        "#stop words IDENTIFYING\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop= stopwords.words('english')\n",
        "stop\n",
        "#manually removing repeating stopwords such as companuy name\n",
        "stop.append('unlock')\n",
        "\n",
        "#REMOVING STOPWORDS FROM DF COPY\n",
        "df_copy['COMMENTS']=df_copy[\"COMMENTS\"].apply(lambda x:\" \".join(x for x in x.split() if x not in stop))\n",
        "df_copy['COMMENTS'].head()\n",
        "#stemming \n",
        "from nltk.stem import PorterStemmer\n",
        "st=PorterStemmer()\n",
        "df_copy['COMMENTS']=df_copy['COMMENTS'].apply(lambda x:\" \".join([st.stem(word) for word in x.split()]))\n",
        "#text data has been cleaned\n",
        "\n",
        "#bring new data into old bag od words created\n",
        "feature_list= cv.get_feature_names()\n",
        "vect= CountVectorizer(vocabulary= feature_list)\n",
        "x=vect.transform(df_copy['COMMENTS']).toarray()\n",
        "y_pred=clf.predict(x)\n",
        "y_pred\n"
      ],
      "metadata": {
        "id": "4hLFpqMhm7M8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bring new data into old bag od words created\n",
        "feature_list= cv.get_feature_names()\n",
        "vect= CountVectorizer(vocabulary= feature_list)\n",
        "x=vect.transform(df_copy['COMMENTS']).toarray()\n",
        "y_pred=clf.predict(x)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "UpDXYfvN8ZF1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}